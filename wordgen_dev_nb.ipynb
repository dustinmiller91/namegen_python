{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_wordlist():\n",
    "    # Grab a table of common baby names from the 1880s\n",
    "    url = 'https://www.ssa.gov/oact/babynames/decades/names1880s.html'\n",
    "    src = requests.get(url).content\n",
    "    \n",
    "    # Basic web scraping to dataframe\n",
    "    soup = bs(src, 'lxml')\n",
    "    table = soup.find_all('table', attrs = {'class' : 't-stripe'})[0]\n",
    "    rows = table.find_all('tr')\n",
    "    \n",
    "    cols = ['RANK', 'MNAME', 'COUNT_1', 'FNAME', 'COUNT_2']\n",
    "    df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    # Iterate through each row and append it to the dataframe as a pd.Series\n",
    "    for row in rows:\n",
    "        d_ls = [d.text for d in row.find_all('td')]\n",
    "        if len(d_ls) != 5:\n",
    "            continue\n",
    "        df = df.append(pd.Series(d_ls, index = cols), ignore_index = True)\n",
    "    return df['MNAME'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to grab a random key from dictionary based using value weights\n",
    "def select_weighted(d):\n",
    "   offset = random.randint(0, sum(d.values())-1)\n",
    "   for k, v in d.items():\n",
    "      if offset < v:\n",
    "         return k\n",
    "      offset -= v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates a k/v string/weight pair\n",
    "def add_subchunk(freq_dict, subchunk):   \n",
    "    if subchunk in freq_dict.keys():\n",
    "        freq_dict[subchunk] += 1\n",
    "    else:\n",
    "        freq_dict[subchunk] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our model on a word list. Rather than a single pure markov chain, a little extra work has been put in to ensure\n",
    "# correct-seeming beginnings and endings of words.\n",
    "def train(wordlist, depth):\n",
    "    assert depth > 0\n",
    "    dict_start = {}    \n",
    "    dict_general = {}\n",
    "    dict_end = {}\n",
    "    for word in wordlist:\n",
    "        # Count for dict_start\n",
    "        add_subchunk(dict_start, word[0:2])\n",
    "        # Count for dict end\n",
    "        add_subchunk(dict_end, word[-2:]) \n",
    "        # Count for dict_general\n",
    "        for i in range(1, len(word)):\n",
    "            subchunk = word[i-1:i+depth]\n",
    "            add_subchunk(dict_general, subchunk)\n",
    "    # print(dict_start)\n",
    "    return (dict_start, dict_general, dict_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(model, wordlen):\n",
    "    endlen = 2\n",
    "    # Get a starting block from the starting frequency table\n",
    "    word = select_weighted(model[0])\n",
    "    # Continuously add letters based on our general frequency table\n",
    "    while len(word) < wordlen-endlen:\n",
    "        try:\n",
    "            # Filter to chunks with overlap\n",
    "            newDict = {k: v for k, v in model[1].items() if k[0] == word[-1]}\n",
    "            # Add chunk (minus overlapping letter)\n",
    "            word += select_weighted(newDict)[1:]\n",
    "        except:\n",
    "            word = select_weighted(model[0])\n",
    "    # Add an ending chunk, lots of possible screwey edge cases here that have just been wrapped in try/catch blocks.\n",
    "    # Room for improvement, but it works for now.\n",
    "    finished = False\n",
    "    while not finished:\n",
    "        try:\n",
    "            newDict = {k: v for k, v in model[2].items() if k[0] == word[-1]}\n",
    "            word += select_weighted(newDict)[1:]\n",
    "            finished = True\n",
    "        except:\n",
    "            try:\n",
    "                # Filter to chunks with overlap\n",
    "                newDict = {k: v for k, v in model[1].items() if k[0] == word[-1]}\n",
    "                # Add chunk (minus overlapping letter)\n",
    "                word += select_weighted(newDict)[1:]\n",
    "            except:\n",
    "                return word\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = get_test_wordlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(wordlist, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stist\n",
      "Jueliss\n",
      "Clacences\n",
      "Wichah\n",
      "Elsond\n",
      "Penge\n",
      "Sytonk\n",
      "Cerbex\n",
      "Stong\n",
      "Emiliuse\n",
      "Mahalld\n",
      "Miverving\n",
      "Nexande\n",
      "Osterd\n",
      "Wices\n",
      "Geubey\n",
      "Sarree\n",
      "Thardward\n",
      "Frer\n",
      "Lenestt\n",
      "Earlll\n",
      "Elsonn\n",
      "Cllien\n",
      "Hardery\n",
      "Ruellend\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 25):\n",
    "    print(build(model, random.randint(5, 8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
